{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "LS_K_Nearest_Neighbors Algorithm.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7KakOLY4n3pn",
        "colab_type": "text"
      },
      "source": [
        "## LS_K_Nearest_Neighbors Class"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f7nFzByc0h66",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import scipy as sp"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oiQ-9jNf0aLY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class LS_K_Nearest_Neighbors():\n",
        "\n",
        "  # To begin we need to determine our variables, the amount of neighbors that we will \n",
        "  # measure data points against, and how the data points will be weighted against\n",
        "  # each other.\n",
        "  \n",
        "  def __init__(self, X_train, y_train, n_neighbors=5, weights='uniform'):\n",
        "\n",
        "    self.X_train = X_train\n",
        "    self.y_train = y_train\n",
        "\n",
        "    self.n_neighbors = n_neighbors\n",
        "    self.weights = weights\n",
        "\n",
        "    self.n_classes = 3\n",
        "\n",
        "\n",
        "  # To start our algorithm, we first need to determine the distance between 2 points.\n",
        "  # These points are the data points that we want to classify and the training \n",
        "  # point that we are using for comparison.\n",
        "  # For this, we are using the common Euclidian distance formula, but others \n",
        "  # could be used as well, such as the Manhattan distance formula\n",
        "\n",
        "  def euclidian_distance(self, a, b):\n",
        "    distance = np.sqrt(np.sum((a - b)**2, axis=1))\n",
        "    return distance\n",
        "\n",
        "\n",
        "  # Of course, we want to make sure that the data is all fit to the model.\n",
        "  def fit(self, X, y):\n",
        "      \"\"\"\n",
        "      X is a list of lists containing data values\n",
        "      y is a list of classifications\n",
        "      \"\"\"\n",
        "\n",
        "      for i in range(len(X)):\n",
        "          # Add the classification to the list with data values\n",
        "          X[i].append(y[i])\n",
        "      return X\n",
        "\n",
        "\n",
        "  # Our next step is to find the neighbors that we want to check in with.\n",
        "  # A KNN model will only work if other data points can be located, and we need \n",
        "  # to work with the closest ones.\n",
        "  # For our purposes, the actual distance value itself between the data points\n",
        "  # is irrelevant, what we need is the order of the data points in terms of how\n",
        "  # close or far they are from the data point we are classifying.\n",
        "  # The euclidean_distance function will do the measuring, and then we have to\n",
        "  # determine the order of these distances, and hence, the order of the data points.\n",
        "\n",
        "  # For the following kneighbors function, the data points that we want to classify\n",
        "  # are part of the test dataset and the rest of the data points are part of the\n",
        "  # training dataset.\n",
        "  # When we measure the distance between a data point in the test dataset and\n",
        "  # the training dataset we store these distance as point distributions in the\n",
        "  # point_dist variable.\n",
        "  # Each row stored in point_dist represents a list of distances between 1 test\n",
        "  # dataset data point against all of the data points in the training dataset.\n",
        "  # After each test dataset data point has been measured against we will\n",
        "  # list (enumerate) and sort each row according to the measured distances.\n",
        "  # It is important to do this for ALL of the rows because we don't want to lose\n",
        "  # the information of the training data points that we calculated the distances\n",
        "  # with. This information will be important when we refer to them later.\n",
        "  # The sorted_neigh variable holds the first nearest neighbors of our test data\n",
        "  # points, sorted accordingly by their measured euclidian distances.\n",
        "  # From sorted_neigh, we extract the indicies and distance values and return them\n",
        "\n",
        "\n",
        "  def kneighbors(self, X_test, return_distance=False):\n",
        "\n",
        "    dist = []\n",
        "    neigh_ind = []\n",
        "\n",
        "    point_dist = [self.euclidian_distance(x_test, self.X_train) for x_test in X_test]\n",
        "\n",
        "    for row in point_dist:\n",
        "      enum_neigh = enumerate(row)\n",
        "      sorted_neigh = sorted(enum_neigh,\n",
        "                            key=lambda x: x[1])[:self.n_neighbors]\n",
        "\n",
        "      ind_list = [tup[0] for tup in sorted_neigh]\n",
        "      dist_list = [tup[1] for tup in sorted_neigh]\n",
        "\n",
        "      dist.append(dist_list)\n",
        "      neigh_ind.append(ind_list)\n",
        "\n",
        "    if return_distance:\n",
        "      return np.array(dist), np.array(neigh_ind)\n",
        "\n",
        "    return np.array(neigh_ind)\n",
        "\n",
        "\n",
        "  # Once the nearest neighbors have been located and measured, we use our\n",
        "  # predict function to attempt to predict the classes that each of our test\n",
        "  # data points belong to. \n",
        "  # The method that we use to determine this differs depending on the criteria\n",
        "  # that we have chosen.\n",
        "  # One of the more important choices that needs to be determined is how the\n",
        "  # data points will be weighed against each other, uniformly or by distance.\n",
        "  # Weighing by uniform involves getting the indices of each neighbor and then\n",
        "  # using the indices to match their corresponding class labels with those from\n",
        "  # the training dataset.\n",
        "  # Each row in the neighbors variable corresponds to the set of neighbors that\n",
        "  # each one of the test data points has.\n",
        "  # The bincount function is then used to find the occurrences of the class labels,\n",
        "  # and to get the index that has the maximum occurrence. This index corresponds\n",
        "  # to the predicted class label.\n",
        "  # Weighing by distance involves finding the mean inverse of the distances\n",
        "  # between each neighbor and calculating the class probabilities for each test\n",
        "  # data point.\n",
        "\n",
        "  def predict(self, X_test):\n",
        "\n",
        "    if self.weights == 'uniform':\n",
        "        neighbors = self.kneighbors(X_test)\n",
        "        y_pred = np.array([\n",
        "            np.argmax(np.bincount(self.y_train[neighbor]))\n",
        "            for neighbor in neighbors\n",
        "        ])\n",
        "\n",
        "        return y_pred\n",
        "\n",
        "    if self.weights == 'distance':\n",
        "\n",
        "      dist, neigh_ind = self.kneighbors(X_test, return_distance=True)\n",
        "\n",
        "      inv_dist = 1 / dist\n",
        "\n",
        "      mean_inv_dist = inv_dist / np.sum(inv_dist, axis=1)[:, np.newaxis]\n",
        "\n",
        "      proba = []\n",
        "\n",
        "      for i, row in enumerate(mean_inv_dist):\n",
        "\n",
        "          row_pred = self.y_train[neigh_ind[i]]\n",
        "\n",
        "          for k in range(self.n_classes):\n",
        "              indices = np.where(row_pred == k)\n",
        "              prob_ind = np.sum(row[indices])\n",
        "              proba.append(np.array(prob_ind))\n",
        "\n",
        "      predict_proba = np.array(proba).reshape(X_test.shape[0],\n",
        "                                              self.n_classes)\n",
        "\n",
        "      y_pred = np.array([np.argmax(item) for item in predict_proba])\n",
        "\n",
        "      return y_pred\n",
        "\n",
        "\n",
        "  # This score function will provide a simple and straightforward accuracy metric\n",
        "  \n",
        "  def score(self, X_test, y_test):\n",
        "      y_pred = self.predict(X_test)\n",
        "\n",
        "      return float(sum(y_pred == y_test)) / float(len(y_test))"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PGUnIWwbn-3j",
        "colab_type": "text"
      },
      "source": [
        "## Testing the LS_K_Nearest_Neighbors Class"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0CZfDiKJ1CG2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn import datasets\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "import pandas as pd"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LlWoaMUBoEfm",
        "colab_type": "text"
      },
      "source": [
        "### Breast Cancer Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pIl63J_L8gE4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 77
        },
        "outputId": "a062121d-cbfd-4193-f979-6912d1bdaf0d"
      },
      "source": [
        "from sklearn.datasets import load_breast_cancer\n",
        "bc_dataset = load_breast_cancer()\n",
        "\n",
        "X = bc_dataset.data\n",
        "y = bc_dataset.target\n",
        "\n",
        "mu = np.mean(X, 0)\n",
        "sigma = np.std(X, 0)\n",
        "X = (X - mu ) / sigma\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\\\n",
        "                X, y, test_size=0.3, random_state=45)\n",
        "\n",
        "LSKNN_classifier = LS_K_Nearest_Neighbors(X_train, y_train, n_neighbors=3)\n",
        "sklearn_classifier = KNeighborsClassifier(n_neighbors=3).fit(X_train, y_train)\n",
        "\n",
        "LSKNN_accuracy = LSKNN_classifier.score(X_test, y_test)\n",
        "sklearn_accuracy = sklearn_classifier.score(X_test, y_test)\n",
        "\n",
        "pd.DataFrame([[LSKNN_accuracy, sklearn_accuracy]],\n",
        "             ['Breast Cancer Accuracy'],    \n",
        "             ['LSKNN Implementation', 'Sklearn\\'s Implementation'])"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>LSKNN Implementation</th>\n",
              "      <th>Sklearn's Implementation</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Breast Cancer Accuracy</th>\n",
              "      <td>0.964912</td>\n",
              "      <td>0.964912</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                        LSKNN Implementation  Sklearn's Implementation\n",
              "Breast Cancer Accuracy              0.964912                  0.964912"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z-7GOV4moHht",
        "colab_type": "text"
      },
      "source": [
        "### Iris Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "utTzV7nr1NCZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 77
        },
        "outputId": "7d78a5d3-1e05-4761-bea1-958a85dc7fab"
      },
      "source": [
        "from sklearn.datasets import load_iris\n",
        "iris_dataset = load_iris()\n",
        "\n",
        "X = iris_dataset.data\n",
        "y = iris_dataset.target\n",
        "\n",
        "mu = np.mean(X, 0)\n",
        "sigma = np.std(X, 0)\n",
        "X = (X - mu ) / sigma\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\\\n",
        "                X, y, test_size=0.3, random_state=45)\n",
        "\n",
        "LSKNN_classifier = LS_K_Nearest_Neighbors(X_train, y_train, n_neighbors=3)\n",
        "sklearn_classifier = KNeighborsClassifier(n_neighbors=3).fit(X_train, y_train)\n",
        "\n",
        "LSKNN_accuracy = LSKNN_classifier.score(X_test, y_test)\n",
        "sklearn_accuracy = sklearn_classifier.score(X_test, y_test)\n",
        "\n",
        "pd.DataFrame([[LSKNN_accuracy, sklearn_accuracy]],\n",
        "             ['Iris Accuracy'],    \n",
        "             ['LSKNN Implementation', 'Sklearn\\'s Implementation'])"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>LSKNN Implementation</th>\n",
              "      <th>Sklearn's Implementation</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Iris Accuracy</th>\n",
              "      <td>0.955556</td>\n",
              "      <td>0.955556</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "               LSKNN Implementation  Sklearn's Implementation\n",
              "Iris Accuracy              0.955556                  0.955556"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LQXbM2oboJkv",
        "colab_type": "text"
      },
      "source": [
        "### Wine Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kv5MGjpa63Iz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 77
        },
        "outputId": "c963b3d3-5a14-4e8e-d970-e0afaffdafda"
      },
      "source": [
        "from sklearn.datasets import load_wine\n",
        "wine_dataset = load_wine()\n",
        "\n",
        "X = wine_dataset.data\n",
        "y = wine_dataset.target\n",
        "\n",
        "mu = np.mean(X, 0)\n",
        "sigma = np.std(X, 0)\n",
        "X = (X - mu ) / sigma\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\\\n",
        "                X, y, test_size=0.3, random_state=45)\n",
        "\n",
        "LSKNN_classifier = LS_K_Nearest_Neighbors(X_train, y_train, n_neighbors=3)\n",
        "sklearn_classifier = KNeighborsClassifier(n_neighbors=3).fit(X_train, y_train)\n",
        "\n",
        "LSKNN_accuracy = LSKNN_classifier.score(X_test, y_test)\n",
        "sklearn_accuracy = sklearn_classifier.score(X_test, y_test)\n",
        "\n",
        "pd.DataFrame([[LSKNN_accuracy, sklearn_accuracy]],\n",
        "             ['Wine Accuracy'],    \n",
        "             ['LSKNN Implementation', 'Sklearn\\'s Implementation'])"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>LSKNN Implementation</th>\n",
              "      <th>Sklearn's Implementation</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Wine Accuracy</th>\n",
              "      <td>0.981481</td>\n",
              "      <td>0.981481</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "               LSKNN Implementation  Sklearn's Implementation\n",
              "Wine Accuracy              0.981481                  0.981481"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mcWJi-4f9kdz",
        "colab_type": "text"
      },
      "source": [
        "Blog Site: https://rctom168.github.io/2015-02-26-flake-it-till-you-make-it/\n",
        "\n",
        "* When I make a new blog post it does not appear for some reason.\n",
        "* When I rename this blog post, it disappears. \n",
        "* So unfortunately, the best that I can do is update this blog post to reflect this project, but the name can't be changed.\n",
        "* 2020-06-26 LS_K_Nearest_Neighbors Algorithm.md"
      ]
    }
  ]
}